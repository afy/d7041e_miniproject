{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D7041E Miniproject\n",
    "\n",
    "Group ID: MINI-PROJECT 14\n",
    "\n",
    "Ahmad Allahham\n",
    "[ahmall-0@student.ltu.se] | 940120-0556 |\n",
    "\n",
    "Arian Asghari\n",
    "[ariasg-0@student.ltu.se] | 010721-7051 |\n",
    "\n",
    "Hannes Furhoff\n",
    "[hanfur-0@student.ltu.se] | 010929-4710 |\n",
    "\n",
    "## Grade requirements\n",
    "### G3: Run and understand a publicly available model on a one selected dataset.\n",
    "We have chosen to work with the MLP model (regressive).\n",
    "\n",
    "### G3: Choose a dataset.\n",
    "Our data set is a collection of synthetic housing data, with various parameters (eg. rooms, year built) and price.\n",
    "\n",
    "### G3: Implement tutorial.\n",
    "NOT DONE YET\n",
    "\n",
    "### G3: Test performance for different configurations of the perceptron.\n",
    "NOT DONE YET\n",
    "\n",
    "### G3: Document the performance.\n",
    "NOT DONE YET\n",
    "\n",
    "### G4: You should use data pre-processing\n",
    "For preprocessing a few steps were done:\n",
    "- Converting all values to float type.\n",
    "- Encoding the categorical \"neighborhood\" column to one-hot and then to float.\n",
    "\n",
    "### G4: Systematically choose the hyper-parameters of the model\n",
    "NOT DONE YET\n",
    "\n",
    "### G4: Use cross-validation for training \n",
    "NOT DONE YET\n",
    "\n",
    "### G4: Use different seeds and  recorded performance statistics with various performance metrics\n",
    "NOT DONE YET\n",
    "\n",
    "\n",
    "## Additional info\n",
    "Github link: `https://github.com/afy/d7041e_miniproject` <br/>\n",
    "Dataset link: `https://www.kaggle.com/datasets/muhammadbinimran/housing-price-prediction-data` <br/>\n",
    "Based on tutorial: `https://machinelearningmastery.com/building-a-regression-model-in-pytorch/` <br/>\n",
    "Youtube demo link: `NOT DONE YET` <br/>\n",
    "\n",
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "\n",
    "# Returns from run\n",
    "class ModelMetrics:\n",
    "    def __init__(self, _mse, _rmse, _mae, _time, _settings):\n",
    "        self.mse = _mse\n",
    "        self.rmse = _rmse\n",
    "        self.mae = _mae\n",
    "        self.training_time = _time\n",
    "        self.run_settings = _settings # The settings the model was run on\n",
    "\n",
    "# Settings given to the training function\n",
    "class ModelSettings:\n",
    "    def __init__(self, _layers, _epochs, _batch):\n",
    "        self.layers = _layers\n",
    "        self.epochs = _epochs\n",
    "        self.batch_size = _batch\n",
    "        self.optimizer_learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "\n",
    "# Read data\n",
    "raw_data = np.loadtxt(\"housing_data.csv\", delimiter=\",\", dtype=str)\n",
    "column_names = raw_data[0]\n",
    "raw_data = raw_data[1:]\n",
    "\n",
    "# For \"Neighborhood\" column:\n",
    "# Str -> OH-encoding -> str repr -> float repr \n",
    "# Eg. \"Urban\" -> [0 1 0] -> \"010\" -> (0)10.0\n",
    "d = raw_data[:,3].reshape(-1, 1)\n",
    "oh_enc = OneHotEncoder(dtype=int)\n",
    "oh_enc.fit(d)\n",
    "oh_d = oh_enc.transform(d).toarray().astype(str)\n",
    "for r in range(len(oh_d)):\n",
    "    tf = int(''.join(oh_d[r]))\n",
    "    raw_data[r,3] = tf\n",
    "\n",
    "# Type convert data\n",
    "raw_data = raw_data.astype(float)\n",
    "housing_data, housing_prices = raw_data[:,0:5], raw_data[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "\n",
    "def evaluateModel(settings: ModelSettings, data_train: np.ndarray, data_test: np.ndarray) -> ModelMetrics:\n",
    "    seq =  nn.Sequential(\n",
    "      nn.Conv2d(1, 10, kernel_size=3),\n",
    "      nn.ReLU(),\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(26 * 26 * 10, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 10)\n",
    "    )\n",
    "\n",
    "    optimizer = optim.Adam(seq.parameters(), lr = settings.optimizer_learning_rate) \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "\n",
    "def k_fold_validation(k: int, data: np.ndarray, prices: np.ndarray, settings: ModelSettings) -> ModelMetrics:\n",
    "    return evaluateModel(settings, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001D4D520C3C0>\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "\n",
    "# Running params\n",
    "# The idea is to cycle through the permutations of these\n",
    "k_folds = 3                             # For cross-fold validation\n",
    "layer_length = [1, 3]                   # 1 'layer' = 1 neuron + activation in sequence\n",
    "in_features_sizes = [1, 4, 8, 12, 16, 24, 48, 64, 128]            # Sizes of linear features per-layer\n",
    "out_features_sizes = [1, 4, 8, 12, 16, 24, 48, 64, 128]           # - || -\n",
    "\n",
    "# Other params\n",
    "max_saved_runs = 10\n",
    "\n",
    "# Setup\n",
    "possible_layers = [i for i in range(layer_length[0], layer_length[1] + 1)]\n",
    "best_runs = np.ndarray(max_saved_runs).astype(object)\n",
    "\n",
    "# Train and test model for all argument combinations\n",
    "# Save the {max_saved_runs} best runs\n",
    "combos = itertools.product(possible_layers, in_features_sizes, out_features_sizes)\n",
    "\n",
    "for argcomb in combos:\n",
    "    l_order = []\n",
    "    for li in range(argcomb[0]):\n",
    "        l_order.append(nn.Linear(1, 1))\n",
    "        l_order.append(nn.ReLU)\n",
    "\n",
    "    settings = ModelSettings(\n",
    "        l_order,\n",
    "        100,\n",
    "        10\n",
    "    )\n",
    "    m = k_fold_validation(k_folds, housing_data, housing_prices, settings)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'rmse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[163], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(best_runs\u001b[38;5;241m.\u001b[39msize):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mbest_runs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmse\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'rmse'"
     ]
    }
   ],
   "source": [
    "for r in range(best_runs.size):\n",
    "    print(best_runs[r].rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
